{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7900ed43-1fbd-4d66-b7d7-ba1025feaccb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in c:\\users\\admin\\anaconda3\\lib\\site-packages (1.53.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from openai) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from openai) (0.27.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from openai) (2.8.2)\n",
      "Requirement already satisfied: sniffio in c:\\users\\admin\\anaconda3\\lib\\site-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from openai) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from openai) (4.11.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
      "Requirement already satisfied: certifi in c:\\users\\admin\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\admin\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.20.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "id": "7ecec055-6b79-4b26-b4f8-3e2f3b7a5e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "from pathlib import Path\n",
    "\n",
    "api_key = \"\" \n",
    "client = OpenAI(api_key=api_key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "id": "cb3fbe5e-7314-492f-a7a9-48b05b83f66e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FileObject(id='file-Fj0GyMp1ZrJMYGFnwKVGum33', bytes=19760, created_at=1732091987, filename='quiz_format.jsonl', object='file', purpose='fine-tune', status='processed', status_details=None)"
      ]
     },
     "execution_count": 513,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.files.create(\n",
    "    file=Path(\"quiz_format.jsonl\"),\n",
    "    purpose=\"fine-tune\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "id": "3cb492f8-fe55-4344-9af4-60642ed7c14c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FineTuningJob(id='ftjob-B5imSfQrxFb35oBfa8RaC9CE', created_at=1732091992, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs=2, batch_size='auto', learning_rate_multiplier='auto'), model='gpt-4o-2024-08-06', object='fine_tuning.job', organization_id='org-mzKEKjPTDzVL4GIR0reinzMC', result_files=[], seed=2138788366, status='validating_files', trained_tokens=None, training_file='file-Fj0GyMp1ZrJMYGFnwKVGum33', validation_file=None, estimated_finish=None, integrations=[], user_provided_suffix=None)\n"
     ]
    }
   ],
   "source": [
    "response = client.fine_tuning.jobs.create(\n",
    "    training_file = \"file-Fj0GyMp1ZrJMYGFnwKVGum33\",\n",
    "    model = \"gpt-4o-2024-08-06\",\n",
    "    hyperparameters={\n",
    "    \"n_epochs\":2\n",
    "    }\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "id": "7466fca9-d0cd-4be6-890b-e2955f220dbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ft:gpt-4o-2024-08-06:hm::AVafp0Bq\n"
     ]
    }
   ],
   "source": [
    "response = client.fine_tuning.jobs.retrieve(\"ftjob-B5imSfQrxFb35oBfa8RaC9CE\")\n",
    "\n",
    "if response.status == \"succeeded\" :\n",
    "    print(response.fine_tuned_model)\n",
    "else:\n",
    "    print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "id": "f7d59218-a53b-4c98-be9e-e8aad73c3af2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def generate_quiz(topic):\n",
    "    prompt = f\"Create difficult 3-5 question MCQ quiz on the following question: {topic},do not add anything other than the questions\"\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"ft:gpt-4o-2024-08-06:hm::AVafp0Bq\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        n=1,\n",
    "    )\n",
    "    #print(\"Tokens used:\", response.usage.total_tokens)\n",
    "    return response.choices[0].message.content\n",
    "    \n",
    "\n",
    "def quiz_answers(prompt):\n",
    "    prompt = f\"Answers to the quiz \\n{quiz} \\n give the answers in this format [A,B,C,D,A]\"\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"ft:gpt-4o-2024-08-06:hm::AVafp0Bq\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        n=1,\n",
    "        temperature=0\n",
    "    )\n",
    "    #print(\"Tokens used:\", response.usage.total_tokens)\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "def grade_quiz(quiz_answer, user_answer):\n",
    "    prompt = f\"Mark the following quiz answers: \\nCorrect answers: {quiz_answer} \\nUser's answers: {user_answer} \\nScore the user's answers out of 100%, only return the score as a percentage.\"\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"ft:gpt-4o-2024-08-06:hm::AVafp0Bq\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        n=1,\n",
    "        temperature=0\n",
    "    )\n",
    "    #print(\"Tokens used:\", response.usage.total_tokens)\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "def assign_skill_level(quiz_score):\n",
    "  if quiz_score >= 90:\n",
    "    return \"Advanced\"\n",
    "  elif quiz_score >= 70:\n",
    "    return \"Intermediate\"\n",
    "  else:\n",
    "    return \"Beginner\"\n",
    "\n",
    "def adjust_quiz_difficulty(quiz_score):\n",
    "  if quiz_score >= 100:\n",
    "    return \"Much more difficult\"\n",
    "  elif quiz_score >= 90:\n",
    "      return \"More difficult\"\n",
    "  elif quiz_score >= 70:\n",
    "    return \"Slightly more difficult\"\n",
    "  elif quiz_score >= 50:\n",
    "      return \"Similar\"\n",
    "  else:\n",
    "    return \"Slightly easier\"\n",
    "\n",
    "def generate_additional_quiz(quiz, new_difficulty, topic,max_tokens=130):\n",
    "    prompt = f\"Using this quiz as a base \\n {quiz} \\n create a {new_difficulty} quiz on {topic}, \\n(MCQ Only, do not give the answers)\"\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"ft:gpt-4o-2024-08-06:hm::AVafp0Bq\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        max_tokens=max_tokens,\n",
    "        n=1\n",
    "    )\n",
    "    #print(\"Tokens used:\", response.usage.total_tokens)\n",
    "    return response.choices[0].message.content\n",
    "    \n",
    "\n",
    "def explain_answers(quiz, quiz_answers, user_answer, max_tokens = 150):\n",
    "    prompt = f\"Explain any question that the user got wrong in this quiz \\n {quiz}, \\n these are the answers \\n {quiz_answers} and this is the user's answers \\n {user_answer} \\n explain how to get the answers \\n ONLY explain incorrect answers\"\n",
    "    response = client.chat.completions.create(\n",
    "    model=\"ft:gpt-4o-2024-08-06:hm::AVafp0Bq\",\n",
    "    messages=[{\"role\":\"user\",\"content\":prompt}],\n",
    "    n=1,\n",
    "    temperature = 0.5\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "def respond_to_query(query, max_tokens=100):\n",
    "    prompt = f\"{query}\"\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"ft:gpt-4o-2024-08-06:hm::AVafp0Bq\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        max_tokens = max_tokens,\n",
    "        n=1\n",
    "    )\n",
    "    #print(\"Tokens used:\", response.usage.total_tokens)\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "def quiz_question_difficulty(quiz):\n",
    "    prompt = f\"Rate the difficulty of each question in this quiz out of 10 \\n{quiz} \\n follow this format [0.2,1,5,8,10]\"\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"ft:gpt-4o-2024-08-06:hm::AVafp0Bq\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature = 0,\n",
    "        n=1\n",
    "    )\n",
    "    #print(\"Tokens used:\", response.usage.total_tokens)\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "def get_topic_difficulty(topic):\n",
    "    prompt = f\"Rate the difficulty of this topic: {topic}, 10 being the most difficult, only give a number\"\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"ft:gpt-4o-2024-08-06:hm::AVafp0Bq\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature = 0,\n",
    "        n=1\n",
    "    )\n",
    "    #print(\"Tokens used:\", response.usage.total_tokens)\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "id": "26191b12-fcae-48d9-9309-8b559afda007",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. What is the output of the following code?\n",
      "```python\n",
      "def func(a, b=[]):\n",
      "    b.append(a)\n",
      "    return b\n",
      "\n",
      "print(func(1))\n",
      "print(func(2))\n",
      "```\n",
      "A) [1] [2]\n",
      "B) [1] [1, 2]\n",
      "C) [2] [1, 2]\n",
      "D) [1, 2] [3]\n",
      "2. Which of the following is a valid way to create a set in Python?\n",
      "A) {1, 2, 3}\n",
      "B) set[1, 2, 3]\n",
      "C) (1, 2, 3)\n",
      "D) [1, 2, 3]\n",
      "3. What will be the result of `all([0, 1, 2])`?\n",
      "A) True\n",
      "B) False\n",
      "C) 1\n",
      "D) SyntaxError\n"
     ]
    }
   ],
   "source": [
    "topic = \"python\"\n",
    "quiz = generate_quiz(topic)\n",
    "print(quiz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "id": "c78f5f6e-1f42-4d11-9065-f5ebbe8a4ac9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "quiz_answer = quiz_answers(quiz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "id": "1deef2e5-9ac5-4591-8278-c767240fd8ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60%\n",
      "Similar\n"
     ]
    }
   ],
   "source": [
    "user_answer = ['','','','','']\n",
    "response = grade_quiz(quiz_answer,user_answer)\n",
    "print(response)\n",
    "quiz_score = float(response.strip('%'))\n",
    "new_difficulty = adjust_quiz_difficulty(quiz_score)\n",
    "print(new_difficulty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "id": "3e2a3d68-74b0-4678-9a01-09bbcce7b822",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. [1]\n",
      "2. [2]\n",
      "3. [1]\n",
      "4. [2]\n",
      "5. [3]\n"
     ]
    }
   ],
   "source": [
    "question_difficulty = quiz_question_difficulty(quiz)\n",
    "print(question_difficulty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "id": "c5c782e4-0b35-4568-a434-a24041df5a60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2. The correct answer is c) Tuple. Tuples are immutable, meaning their elements cannot be changed after they are created. Lists, dictionaries, and sets are mutable.\n",
      "\n",
      "4. The correct answer is a) 4. The expression `num // 2` performs floor division, resulting in 4.0. The `int()` function then converts it to 4.\n"
     ]
    }
   ],
   "source": [
    "response = explain_answers(quiz,quiz_answers,user_answer)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "01cdbc86-7f00-4d69-b261-ddb6686bd710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. What is 5 + 2?\n",
      "A) 6\n",
      "B) 7\n",
      "C) 8\n",
      "D) 9\n",
      "2. What is 6 + 1?\n",
      "A) 6\n",
      "B) 7\n",
      "C) 8\n",
      "D) 9\n",
      "3. What is 4 + 3?\n",
      "A) 6\n",
      "B) 7\n",
      "C) 8\n",
      "D) 9\n"
     ]
    }
   ],
   "source": [
    "additional_quiz = generate_additional_quiz(quiz, new_difficulty,topic)\n",
    "print(additional_quiz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "id": "a0bed238-3f37-46b4-aa54-5e3e7338cb89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. [1]\n",
      "2. [2]\n",
      "3. [1]\n",
      "4. [2]\n",
      "5. [3]\n"
     ]
    }
   ],
   "source": [
    "question_difficulty = quiz_question_difficulty(quiz)\n",
    "print(question_difficulty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "id": "ca496308-cbad-4459-a051-1b73519612f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[B, A, B]\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "print(quiz_answer)\n",
    "topic_difficulty = get_topic_difficulty(topic)\n",
    "print(topic_difficulty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce5bfe1-45b0-461b-969e-8addbd282d49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
