{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7900ed43-1fbd-4d66-b7d7-ba1025feaccb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in c:\\users\\admin\\anaconda3\\lib\\site-packages (1.53.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from openai) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from openai) (0.27.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from openai) (2.8.2)\n",
      "Requirement already satisfied: sniffio in c:\\users\\admin\\anaconda3\\lib\\site-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from openai) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from openai) (4.11.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
      "Requirement already satisfied: certifi in c:\\users\\admin\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\admin\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.20.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7ecec055-6b79-4b26-b4f8-3e2f3b7a5e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "from pathlib import Path\n",
    "\n",
    "api_key = \"\" \n",
    "client = OpenAI(api_key=api_key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cb3fbe5e-7314-492f-a7a9-48b05b83f66e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FileObject(id='file-au3KivxsUPcQr16fXx6br48Y', bytes=14252, created_at=1731485466, filename='quiz_data.jsonl', object='file', purpose='fine-tune', status='processed', status_details=None)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.files.create(\n",
    "    file=Path(\"quiz_data.jsonl\"),\n",
    "    purpose=\"fine-tune\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3cb492f8-fe55-4344-9af4-60642ed7c14c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FineTuningJob(id='ftjob-lit0RjWu67OhgJpZuDhxR1ce', created_at=1731485567, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs=2, batch_size='auto', learning_rate_multiplier='auto'), model='gpt-4o-2024-08-06', object='fine_tuning.job', organization_id='org-mzKEKjPTDzVL4GIR0reinzMC', result_files=[], seed=1801962442, status='validating_files', trained_tokens=None, training_file='file-au3KivxsUPcQr16fXx6br48Y', validation_file=None, estimated_finish=None, integrations=[], user_provided_suffix=None)\n"
     ]
    }
   ],
   "source": [
    "response = client.fine_tuning.jobs.create(\n",
    "    training_file = \"file-au3KivxsUPcQr16fXx6br48Y\",\n",
    "    model = \"gpt-4o-2024-08-06\",\n",
    "    hyperparameters={\n",
    "    \"n_epochs\":2\n",
    "  }\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7466fca9-d0cd-4be6-890b-e2955f220dbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ft:gpt-4o-2024-08-06:hm::AT2tXRi6\n"
     ]
    }
   ],
   "source": [
    "response = client.fine_tuning.jobs.retrieve(\"ftjob-lit0RjWu67OhgJpZuDhxR1ce\")\n",
    "\n",
    "if response.status == \"succeeded\" :\n",
    "    print(response.fine_tuned_model)\n",
    "else:\n",
    "    print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "f7d59218-a53b-4c98-be9e-e8aad73c3af2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def generate_quiz(topic, max_tokens=120):\n",
    "    prompt = f\"Create a simple 3-5 question MCQ quiz on the following question: {topic}, do not add anything other than the questions\\nQuiz:\"\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"ft:gpt-4o-2024-08-06:hm::AT2tXRi6\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        max_tokens=max_tokens,\n",
    "        n=1,\n",
    "    )\n",
    "    #print(\"Tokens used:\", response.usage.total_tokens)\n",
    "    return response.choices[0].message.content\n",
    "    \n",
    "\n",
    "def quiz_answers(prompt , max_tokens =100):\n",
    "    prompt = f\"Give me the answers to the quiz, {quiz}, give me only the correct answers in a single line, nothing else\"\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"ft:gpt-4o-2024-08-06:hm::AT2tXRi6\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        max_tokens=max_tokens,\n",
    "        n=1,\n",
    "        temperature=0\n",
    "    )\n",
    "    #print(\"Tokens used:\", response.usage.total_tokens)\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "def grade_quiz(quiz_answer, user_response, max_tokens =120):\n",
    "    prompt = f\"Mark the following quiz answers: \\nCorrect answers: {quiz_answer} \\nUser's answers: {user_response} \\nScore the user's answers out of 100%, only return the score as a percentage.\"\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"ft:gpt-4o-2024-08-06:hm::AT2tXRi6\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        max_tokens=max_tokens,\n",
    "        n=1,\n",
    "        temperature=0\n",
    "    )\n",
    "    #print(\"Tokens used:\", response.usage.total_tokens)\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "def assign_skill_level(quiz_score):\n",
    "  if quiz_score >= 90:\n",
    "    return \"Advanced\"\n",
    "  elif quiz_score >= 70:\n",
    "    return \"Intermediate\"\n",
    "  else:\n",
    "    return \"Beginner\"\n",
    "\n",
    "def generate_additional_quiz(topic, skill_level, max_tokens=130):\n",
    "    prompt = f\"Create a 2 {skill_level} level MCQ questions on {topic}, do not add anything other than the question\"\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"ft:gpt-4o-2024-08-06:hm::AT2tXRi6\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        max_tokens=max_tokens,\n",
    "        n=1\n",
    "    )\n",
    "    #print(\"Tokens used:\", response.usage.total_tokens)\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "def explain_answers(quiz, quiz_answers, user_response, max_tokens = 150):\n",
    "    prompt = f\"Explain any question that the user got wrong in this quiz \\n {quiz}, \\n these are the answers \\n {quiz_answers} and this is the user's answers \\n {user_response} \\n explain how to get the answers \\n ONLY explain incorrect answers\"\n",
    "    response = client.chat.completions.create(\n",
    "    model=\"ft:gpt-4o-2024-08-06:hm::AT2tXRi6\",\n",
    "    messages=[{\"role\":\"user\",\"content\":prompt}],\n",
    "    n=1,\n",
    "    temperature = 0.5\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "def respond_to_query(query, max_tokens=100):\n",
    "    prompt = f\"{query}\"\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"ft:gpt-4o-2024-08-06:hm::AT2tXRi6\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        max_tokens = max_tokens,\n",
    "        n=1\n",
    "    )\n",
    "    #print(\"Tokens used:\", response.usage.total_tokens)\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "26191b12-fcae-48d9-9309-8b559afda007",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. What is 2 + 2?\n",
      "A) 3\n",
      "B) 4\n",
      "C) 5\n",
      "D) 6\n",
      "\n",
      "2. What is 3 + 5?\n",
      "A) 7\n",
      "B) 8\n",
      "C) 9\n",
      "D) 10\n",
      "\n",
      "3. What is 7 + 1?\n",
      "A) 7\n",
      "B) 8\n",
      "C) 9\n",
      "D) 10\n",
      "\n",
      "4. What is 4 + 6?\n",
      "A) 9\n",
      "B) 10\n",
      "C) 11\n",
      "D) 12\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "topic = \"Basic Addition\"\n",
    "quiz = generate_quiz(topic)\n",
    "print(quiz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "c78f5f6e-1f42-4d11-9065-f5ebbe8a4ac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B, B, B, B\n"
     ]
    }
   ],
   "source": [
    "quiz_answer = quiz_answers(quiz)\n",
    "print(quiz_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "1deef2e5-9ac5-4591-8278-c767240fd8ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75%\n",
      "Intermediate\n"
     ]
    }
   ],
   "source": [
    "user_response = ['a','b','b','b']\n",
    "response = grade_quiz(quiz_answer,user_response)\n",
    "print(response)\n",
    "quiz_score = float(response.strip('%'))\n",
    "skill_level = assign_skill_level(quiz_score)\n",
    "print(skill_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "c5c782e4-0b35-4568-a434-a24041df5a60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To find the correct answer for question 1, add 2 + 2 to get 4, which is option B.\n"
     ]
    }
   ],
   "source": [
    "response = explain_answers(quiz,quiz_answers,user_response)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "01cdbc86-7f00-4d69-b261-ddb6686bd710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. What is the sum of 256 + 178?\n",
      "A) 424\n",
      "B) 434\n",
      "C) 444\n",
      "D) 454\n",
      "\n",
      "2. What is 789 + 123?\n",
      "A) 902\n",
      "B) 912\n",
      "C) 905\n",
      "D) 910\n"
     ]
    }
   ],
   "source": [
    "additiona_quiz = generate_additional_quiz(topic, skill_level)\n",
    "print(additiona_quiz)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0bed238-3f37-46b4-aa54-5e3e7338cb89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
